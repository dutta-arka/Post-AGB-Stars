{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fcfb65e-d742-46f0-8fde-5edf172a1de4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[565507868441719424, 2351623413515105920, 4715635535640762240, 532078488709487360, 4686479751449676032, 351149177434709760, 459182413984008448, 513671461473684352, 433515788197481984, 3303343395568710016, 471908436438311680, 173086700992466688, 255225480926107392, 3238918336374596864, 3388902129107252992, 3422437684728294528, 2968265509022275840, 4758015524139610880, 2902505745786910080, 3334854780347915520, 3336558507975208448, 994259335315643520, 3105987960396950784, 3159640386918214528, 3108327343185135872, 5617989266685365120, 3156171118495247360, 3032030620730261376, 5620444471847839232, 3151417586128916864, 5597822402371118336, 5698817012142459136, 5545800762036628736, 5520238967817034880, 5707613169577769600, 5540178478053582592, 5277809440015969792, 5515266327706463616, 5521628033275348480, 5409069172514684416, 5462428643590805248, 5254793942926363392, 5351904394753372672, 5351069693654349952, 5241806275407841664, 5337582534294739456, 5237007177683569536, 5335866849446446080, 5335709477519159936, 5332682659443937664, 5343168568718268800, 5335675087769798272, 3589047952995134720, 3492184311482349824, 5335102207846402176, 5332853912685160064, 3920735495441657728, 6076326701687231872, 3469106382752903168, 6130448958959242240, 6053621271182676352, 6058372329633216896, 6060828565581083264, 6073662099660289536, 3497154104039422848, 6084869868362934144, 6055883241501706752, 5863599857739835264, 6066902993687172608, 5857811238294426752, 5869845594859880064, 3624198034063995008, 6083719439934104832, 6083708479176016128, 6070128028770373888, 6063703586653222144, 5783415017323438848, 5870113880062711552, 5865398796206273152, 5869018899564351872, 5864661779824561664, 5867561191994328704, 5896479309853592448, 5853777267581362176, 5849962851220246016, 5849958457496943744, 5877302177877393024, 5878583349370477312, 5906408788891928704, 5880708980232408448, 5893945588395282304, 5899715786733345536, 5903310335089068416, 5886573569080505216, 5877154701494366336, 5877096736611221888, 5888049732191403904, 5824126771840487936, 1194929381434604800, 1369896865785991424, 5996617434442714880, 5933063252888145920, 5835411094089870592, 5935061172876722176, 5990014935825542144, 5934701559547878144, 5932016212933920384, 5831295999979910656, 4351018375858237952, 5941189713256986752, 5943899425344608000, 1324742534573959424, 5943047784868946688, 5941041038676090112, 1328057763997734144, 4334241408966611328, 5969973999973524224, 4365451214021224320, 6029425384023553792, 5963059480546004608, 5965575811694758784, 4568163710366782848, 5917195002285834240, 5973374200987325056, 4128590918794710272, 4128590918794710272, 5980714063986945920, 5971985036767008256, 5972460442434579968, 4058987022459300096, 4108072721831278976, 4136944866387751552, 4109870908774509184, 5972489407656030720, 4109553493474085504, 5960186761599871488, 5975007147549090432, 4162959693758887424, 5975083327400970752, 4110550475656804864, 4061265519768800768, 5946845601071213696, 4117592465329067008, 5955201232284272384, 4060159376692627840, 4117263131638476032, 4053492968991830400, 4118178784208141568, 4124125282361429504, 4053880649927702656, 1367102319545324288, 4120637086125583360, 4120632688077368192, 4041945343757244160, 5954670408684703872, 4056355822397882880, 4119492494479957760, 4067343654354938112, 4582795323914832000, 4172337943816530432, 4035783611879028736, 4062759511236966016, 4062301564840251520, 4062817927079802240, 4042544062195042176, 4035907203854415488, 4579182637944779264, 4065774307705264384, 4158154754919296000, 4093773847992815744, 4580154606223711872, 4049331244394134912, 4065347387968755328, 4049379725984965120, 4065322923848085760, 4046476534251259904, 4270080782317422208, 4155847571502019840, 4093689116883710592, 4104509518289438720, 2096072103492979584, 6736747708089687936, 4099619470274753408, 4508727788268978176, 4072427555640528000, 4253622708258596736, 4266422531037747200, 4285847607265349632, 4252449701157768960, 4203848980711226112, 4282499452616310912, 4265817151122002688, 4080575933190651008, 6715619076008049792, 4293369057089082112, 4264026012336768000, 4520072476226779520, 6435349718091211264, 4515084168071571840, 2049984454412871296, 4516723883521069952, 2018131400704379648, 6744366945682210560, 4318134628803970816, 2025220089635846528, 1825500124644105728, 2032744769234150016, 2032364166432389760, 4301238979044890496, 2020388045260203008, 2022052808961769088, 4240112390324832384, 4318934003785783680, 2049034819957965312, 2031794791233840128, 2033763428091006720, 2020571869841643392, 2026709201998745472, 6871175064823382912, 2074302426124470656, 6879196723703009920, 2034134414507432064, 2030200671149815424, 4190636669164572928, 2055174630333744384, 2060806470651334912, 1803364717856260736, 2060616220769708672, 1836195688380634368, 2054521833963867008, 2056435602670418688, 1859190569633451648, 1869422453048750336, 2193902559325301760, 2197298400984984064, 1731164844433296128, 2168803045330976768, 2179471159976791168, 6831062200578042624, 6616993471402951680, 6824212243136821248, 1976077657917533952, 2005246464463628800, 1958757291756223104, 2006425553228658816, 2594762641717531008, 6385794694664872320, 1932229409071269248, 2015785313459952128]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "file_path = \"post_AGB.csv\"  # Replace with your actual file path\n",
    "\n",
    "# Load the CSV files\n",
    "df = pd.read_csv(file_path, delimiter=',')\n",
    "\n",
    "# Extract Gaia source IDs from the other CSV file (assuming it's the first column)\n",
    "ids_to_keep = set(df.iloc[:, 0].astype(str))\n",
    "\n",
    "# Filter rows in df based on conditions\n",
    "filtered_df = df[(df['Vickers category'] <= 3)]\n",
    "\n",
    "# Keep only those rows where the Gaia source ID is in ids_to_keep and the last column is not empty\n",
    "filtered_df = filtered_df[filtered_df.iloc[:, -1].notna() & filtered_df.iloc[:, 0].astype(str).isin(ids_to_keep)]\n",
    "\n",
    "# Extract the first column (Gaia source ID)\n",
    "first_column_list = filtered_df.iloc[:, 0].tolist()\n",
    "\n",
    "# Print the list of first column values\n",
    "print(first_column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e6bb62d-4a06-4077-b4a2-66fad6c27cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaiadr3_ids = first_column_list\n",
    "len(gaiadr3_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eacc4a84-b1a9-493e-a0ea-5330fe3b118d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pyvo version 1.5.2 \n",
      "\n",
      "TAP service APPLAUSE \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pyvo as vo\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameters\n",
    "name = 'APPLAUSE'\n",
    "url = 'https://www.plate-archive.org/tap'\n",
    "token = 'Token d62cc50a37a9d01149f6de294ee9ab0193207569'\n",
    "\n",
    "# Function to chunk the list into groups of specified size\n",
    "def chunk_list(data_list, chunk_size):\n",
    "    for i in range(0, len(data_list), chunk_size):\n",
    "        yield data_list[i:i + chunk_size]\n",
    "\n",
    "# Function to process each chunk\n",
    "def process_chunk(chunk):\n",
    "    # Format the gaiaedr3_id list for the SQL query\n",
    "    ids_str = ', '.join(f\"'{id}'\" for id in chunk)\n",
    "    \n",
    "    # Create the query string\n",
    "    qstr = f\"\"\"\n",
    "    SELECT plate_id, scan_id, source_id, solution_num, gaiaedr3_id\n",
    "    FROM applause_dr4.source_xmatch \n",
    "    WHERE gaiaedr3_id IN ({ids_str})\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup the TAP service session\n",
    "    tap_session = requests.Session()\n",
    "    tap_session.headers['Authorization'] = token\n",
    "    tap_service = vo.dal.TAPService(url, session=tap_session)\n",
    "    \n",
    "    # Submit the query\n",
    "    lang = 'PostgreSQL'\n",
    "    job = tap_service.submit_job(qstr, language=lang, QUEUE=\"1h\")\n",
    "    job.run()\n",
    "    \n",
    "    # Wait for job completion\n",
    "    job.wait(phases=[\"COMPLETED\", \"ERROR\", \"ABORTED\"], timeout=600.)\n",
    "    \n",
    "    # Raise an error if the job failed\n",
    "    job.raise_if_error()\n",
    "    \n",
    "    # Fetch results\n",
    "    return job.fetch_result()\n",
    "\n",
    "# Print pyvo version and TAP service name\n",
    "print('\\npyvo version %s \\n' % vo.__version__)\n",
    "print('TAP service %s \\n' % name)\n",
    "\n",
    "# Initialize the result dictionary\n",
    "gaiaedr3_to_plates = {}\n",
    "\n",
    "# Function to process chunks with retries\n",
    "def process_chunks_with_retries(gaiadr3_ids, chunk_size, max_retries=3):\n",
    "    for chunk in chunk_list(gaiadr3_ids, chunk_size):\n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                results = process_chunk(chunk)\n",
    "                # Process results into a dictionary\n",
    "                for row in results:\n",
    "                    gaiaedr3_id = str(row['gaiaedr3_id'])  # Convert to string\n",
    "                    plate_info = {\n",
    "                        'plate_id': row['plate_id'],\n",
    "                        'source_id': row['source_id'],\n",
    "                        'scan_id': row['scan_id'],\n",
    "                        'solution_num': row['solution_num']\n",
    "                    }\n",
    "                    if gaiaedr3_id not in gaiaedr3_to_plates:\n",
    "                        gaiaedr3_to_plates[gaiaedr3_id] = []\n",
    "                    gaiaedr3_to_plates[gaiaedr3_id].append(plate_info)\n",
    "                break  # Exit the retry loop if processing is successful\n",
    "            except Exception as e:\n",
    "                retries += 1\n",
    "                print(f\"Error processing chunk {chunk} (retry {retries}/{max_retries}): {e}\")\n",
    "                if retries == max_retries:\n",
    "                    print(f\"Failed to process chunk after {max_retries} retries. Skipping to next chunk.\")\n",
    "\n",
    "# Process all chunks with retries\n",
    "process_chunks_with_retries(gaiadr3_ids, chunk_size=150)\n",
    "\n",
    "# Print the resulting dictionary\n",
    "# print(gaiaedr3_to_plates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f316ac48-7034-41f5-8027-fbfef41003f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to pAGB_gaiaedr3_to_plates_fL.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a custom encoder class\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "# Assuming 'gaiaedr3_to_plates_selected' is your dictionary\n",
    "with open('pAGB_gaiaedr3_to_plates_fL.txt', 'w') as file:\n",
    "    json.dump(gaiaedr3_to_plates, file, indent=4, ensure_ascii=False, cls=NumpyEncoder)\n",
    "\n",
    "print('Dictionary saved to pAGB_gaiaedr3_to_plates_fL.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aaf0af1-12b4-42fd-b132-c93886cbb341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import json\n",
    "import pyvo as vo\n",
    "\n",
    "# Define the parameters\n",
    "url = 'https://www.plate-archive.org/tap'\n",
    "token = 'Token d62cc50a37a9d01149f6de294ee9ab0193207569'\n",
    "\n",
    "# Function to chunk the list into groups of specified size\n",
    "def chunk_list(data_list, chunk_size):\n",
    "    for i in range(0, len(data_list), chunk_size):\n",
    "        yield data_list[i:i + chunk_size]\n",
    "\n",
    "# Read the gaiaedr3_to_plates.txt file to obtain source_ids\n",
    "with open('pAGB_gaiaedr3_to_plates_fL.txt', 'r') as file\n",
    "    gaiaedr3_to_plates = json.load(file)\n",
    "\n",
    "# Extract source_ids from gaiaedr3_to_plates dictionary\n",
    "source_ids = [entry['source_id'] for entries in gaiaedr3_to_plates.values() for entry in entries]\n",
    "\n",
    "# Initialize dictionary to store calibration information for each source_id\n",
    "source_calib_info = {}\n",
    "\n",
    "# Setup a retry strategy\n",
    "retry_strategy = Retry(\n",
    "    total=3,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[429, 500, 502, 503, 504]\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "session = requests.Session()\n",
    "session.mount(\"https://\", adapter)\n",
    "session.headers['Authorization'] = token\n",
    "\n",
    "# Initialize TAP service\n",
    "tap_service = vo.dal.TAPService(url, session=session)\n",
    "lang = 'PostgreSQL'\n",
    "\n",
    "# Function to process each chunk for source calibration information\n",
    "def process_source_calib_chunk(chunk):\n",
    "    # Format the source_id list for the SQL query\n",
    "    ids_str = ', '.join(f\"'{id}'\" for id in chunk)\n",
    "    \n",
    "    # Create the query string\n",
    "    qstr = f\"\"\"\n",
    "    SELECT bpmag, bpmag_error, rpmag, rpmag_error, natmag, natmag_error, natmag_plate, natmag_correction, natmag_residual, source_id, gaiaedr3_id, airmass, zenith_angle, ra_icrs, dec_icrs, phot_calib_flags, gaiaedr3_gmag, gaiaedr3_bp_rp, gaiaedr3_dist, cat_natmag\n",
    "    FROM applause_dr4.source_calib \n",
    "    WHERE source_id IN ({ids_str}) AND phot_calib_flags = 0\n",
    "    \"\"\"\n",
    "    \n",
    "    # Submit the query\n",
    "    job = tap_service.submit_job(qstr, language=lang, QUEUE=\"1h\")\n",
    "    job.run()\n",
    "    \n",
    "    # Wait for job completion\n",
    "    job.wait(phases=[\"COMPLETED\", \"ERROR\", \"ABORTED\"], timeout=600.)\n",
    "    \n",
    "    # Raise an error if the job failed\n",
    "    job.raise_if_error()\n",
    "    \n",
    "    # Fetch results\n",
    "    return job.fetch_result()\n",
    "\n",
    "# Function to process chunks with retries\n",
    "def process_chunks_with_retries(source_ids, chunk_size, max_retries=3):\n",
    "    for chunk in chunk_list(source_ids, chunk_size):\n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                results = process_source_calib_chunk(chunk)\n",
    "                # Process results into a dictionary\n",
    "                for row in results:\n",
    "                    source_id = str(row['source_id'])\n",
    "                    calib_info = {\n",
    "                        'gaiaedr3_id': row['gaiaedr3_id'],\n",
    "                        'bpmag': row['bpmag'],\n",
    "                        'bpmag_error': row['bpmag_error'],\n",
    "                        'rpmag': row['rpmag'],\n",
    "                        'rpmag_error': row['rpmag_error'],\n",
    "                        'natmag': row['natmag'],\n",
    "                        'natmag_error': row['natmag_error'],\n",
    "                        'natmag_plate': row['natmag_plate'],\n",
    "                        'natmag_correction': row['natmag_correction'],\n",
    "                        'natmag_residual': row['natmag_residual'],\n",
    "                        'cat_natmag': row['cat_natmag'],\n",
    "                        'airmass': row['airmass'],\n",
    "                        'zenith_angle': row['zenith_angle'],\n",
    "                        'ra_icrs': row['ra_icrs'],\n",
    "                        'dec_icrs': row['dec_icrs'],\n",
    "                        'phot_calib_flags': row['phot_calib_flags'],\n",
    "                        'gaiaedr3_gmag': row['gaiaedr3_gmag'],\n",
    "                        'gaiaedr3_bp_rp': row['gaiaedr3_bp_rp'],\n",
    "                        'gaiaedr3_dist': row['gaiaedr3_dist']\n",
    "                    }\n",
    "                    source_calib_info[source_id] = calib_info\n",
    "                break  # Exit the retry loop if processing is successful\n",
    "            except Exception as e:\n",
    "                retries += 1\n",
    "                print(f\"Error processing chunk {chunk} (retry {retries}/{max_retries}): {e}\")\n",
    "                if retries == max_retries:\n",
    "                    print(f\"Failed to process chunk after {max_retries} retries. Skipping to next chunk.\")\n",
    "\n",
    "# Process all chunks with retries\n",
    "process_chunks_with_retries(source_ids, chunk_size=200)\n",
    "\n",
    "# Print the resulting dictionary\n",
    "# print(source_calib_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42cb4525-55d3-404f-8c56-640682ada569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source calibration information saved to pAGB_source_calib_info_fL.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a custom encoder class\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "# Save the source calibration information to a .txt file in JSON format\n",
    "with open('pAGB_source_calib_info_fL.txt', 'w') as file:\n",
    "    json.dump(source_calib_info, file, indent=4, ensure_ascii=False, cls=NumpyEncoder)\n",
    "\n",
    "print('Source calibration information saved to pAGB_source_calib_info_fL.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e07f3d6-1203-494d-857d-704e4e279493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique plates: 18902\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pyvo as vo\n",
    "import json\n",
    "\n",
    "# Define the parameters\n",
    "name = 'APPLAUSE'\n",
    "url = 'https://www.plate-archive.org/tap'\n",
    "token = 'Token d62cc50a37a9d01149f6de294ee9ab0193207569'\n",
    "\n",
    "# Function to chunk the list into groups of specified size\n",
    "def chunk_list(data_list, chunk_size):\n",
    "    for i in range(0, len(data_list), chunk_size):\n",
    "        yield data_list[i:i + chunk_size]\n",
    "\n",
    "# Function to process the plate details query\n",
    "def process_plate_details_query(plate_ids):\n",
    "    # Format the plate_id list for the SQL query\n",
    "    ids_str = ', '.join(f\"'{id}'\" for id in plate_ids)\n",
    "    \n",
    "    # Create the query string\n",
    "    qstr = f\"\"\"\n",
    "    SELECT plate_id, plate_num, plate_quality, date_orig, observatory, air_temperature\n",
    "    FROM applause_dr4.plate\n",
    "    WHERE plate_id IN ({ids_str})\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup the TAP service session\n",
    "    tap_session = requests.Session()\n",
    "    tap_session.headers['Authorization'] = token\n",
    "    tap_service = vo.dal.TAPService(url, session=tap_session)\n",
    "    \n",
    "    # Submit the query\n",
    "    lang = 'PostgreSQL'\n",
    "    job = tap_service.submit_job(qstr, language=lang, QUEUE=\"1h\")\n",
    "    job.run()\n",
    "    \n",
    "    # Wait for job completion\n",
    "    job.wait(phases=[\"COMPLETED\", \"ERROR\", \"ABORTED\"], timeout=600.)\n",
    "    \n",
    "    # Raise an error if the job failed\n",
    "    job.raise_if_error()\n",
    "    \n",
    "    # Fetch results\n",
    "    return job.fetch_result()\n",
    "\n",
    "# Read the pAGB_gaiaedr3_to_plates_fL.txt file\n",
    "with open('pAGB_gaiaedr3_to_plates_fL.txt', 'r') as file:\n",
    "    gaiaedr3_to_plates = json.load(file)\n",
    "\n",
    "# Extract all unique plate_ids\n",
    "plate_ids = set()\n",
    "for plate_list in gaiaedr3_to_plates.values():\n",
    "    for plate_info in plate_list:\n",
    "        plate_ids.add(plate_info['plate_id'])\n",
    "\n",
    "# Notify the total number of unique plates\n",
    "total_plates = len(plate_ids)\n",
    "print(f'Total number of unique plates: {total_plates}')\n",
    "\n",
    "# Initialize list to hold all plate details\n",
    "all_plate_details = []\n",
    "\n",
    "# Process each chunk of plate_ids\n",
    "for chunk in chunk_list(list(plate_ids), 150):\n",
    "    results = process_plate_details_query(chunk)\n",
    "    \n",
    "    # Convert results to a list of dictionaries and add to the main list\n",
    "    for row in results:\n",
    "        all_plate_details.append({\n",
    "            'plate_id': row['plate_id'],\n",
    "            'plate_num': row['plate_num'],\n",
    "            'plate_quality': row['plate_quality'],\n",
    "            'date_orig': row['date_orig'],\n",
    "            'observatory': row['observatory'],\n",
    "            'air_temperature': row['air_temperature']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85318f01-9a6c-4eb8-b25c-8131062234bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique plate details saved to pAGB_unique_plate_details.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the unique plate details to a new .txt file in JSON format\n",
    "with open('pAGB_unique_plate_details_fL.txt', 'w') as file:\n",
    "    json.dump(all_plate_details, file, indent=4, ensure_ascii=False, cls=NumpyEncoder)\n",
    "\n",
    "print('Unique plate details saved to pAGB_unique_plate_details.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb99fb-96da-4e83-98b7-83f21855a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pyvo\n",
    "\n",
    "service_url = 'https://www.plate-archive.org/tap'\n",
    "\n",
    "tap_session = requests.Session()\n",
    "tap_session.headers['Authorization'] = 'Token d62cc50a37a9d01149f6de294ee9ab0193207569'\n",
    "\n",
    "tap_service = pyvo.dal.TAPService(service_url, session=tap_session)\n",
    "completed_jobs = tap_service.get_job_list(phases='COMPLETED')\n",
    "for job in completed_jobs:\n",
    "     job = pyvo.dal.AsyncTAPJob(service_url + '/async/' + job.jobid,\n",
    "session=tap_session)\n",
    "     job.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "448b6490-5fc0-43b9-a1ef-16bcd14dfc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to pAGB_source_calib_date.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def add_plate_ids(source_file, gaia_plate_file, output_file):\n",
    "    with open(source_file, 'r') as f:\n",
    "        source_data = json.load(f)\n",
    "    with open(gaia_plate_file, 'r') as f:\n",
    "        gaia_plate_data = json.load(f)\n",
    "\n",
    "    output_data = {}\n",
    "\n",
    "    for source_id_str, source_info in source_data.items():\n",
    "        gaia_id = source_info.get('gaiaedr3_id')\n",
    "\n",
    "        if gaia_id is not None and gaia_id != 0 and not (isinstance(gaia_id, float) and np.isnan(gaia_id)):\n",
    "            gaia_id_str = str(gaia_id)\n",
    "            if gaia_id_str in gaia_plate_data:\n",
    "                for plate_info in gaia_plate_data[gaia_id_str]:\n",
    "                    plate_source_id = plate_info.get('source_id')\n",
    "                    if int(source_id_str) == plate_source_id:\n",
    "                        source_info[\"plate_id\"] = plate_info.get(\"plate_id\")\n",
    "                        output_data[source_id_str] = source_info\n",
    "                        break # Important: exit inner loop once match is found\n",
    "        else:\n",
    "            output_data[source_id_str] = source_info\n",
    "            output_data[source_id_str][\"plate_id\"] = None\n",
    "\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(output_data, outfile, indent=4)  # indent for pretty printing\n",
    "\n",
    "source_file = 'pAGB_source_calib_info_fL.txt'\n",
    "gaia_plate_file = 'pAGB_gaiaedr3_to_plates_fL.txt'\n",
    "output_file = 'pAGB_source_calib_date.txt'\n",
    "\n",
    "add_plate_ids(source_file, gaia_plate_file, output_file)\n",
    "\n",
    "print(f\"Output written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "941c95b6-3b92-47f4-bb3a-0d2ec5a0e33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to pAGB_source_calib_date_plate.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def add_plate_dates(source_with_plates_file, plate_metadata_file, output_file):\n",
    "    with open(source_with_plates_file, 'r') as f:\n",
    "        source_data = json.load(f)\n",
    "    with open(plate_metadata_file, 'r') as f:\n",
    "        plate_metadata = json.load(f)\n",
    "\n",
    "    plate_dates = {plate['plate_id']: plate['date_orig'] for plate in plate_metadata}\n",
    "    output_data = {}\n",
    "\n",
    "    for source_id_str, source_info in source_data.items():\n",
    "        plate_id = source_info.get('plate_id')\n",
    "\n",
    "        if plate_id is not None:\n",
    "            if plate_id in plate_dates:\n",
    "                source_info['date_orig'] = plate_dates[plate_id]\n",
    "            else:\n",
    "                source_info['date_orig'] = None  # Handle cases where plate ID isn't found\n",
    "        else:\n",
    "            source_info['date_orig'] = None\n",
    "        output_data[source_id_str] = source_info\n",
    "\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(output_data, outfile, indent=4)\n",
    "\n",
    "source_with_plates_file = 'pAGB_source_calib_date.txt'  # Output from the previous step\n",
    "plate_metadata_file = 'pAGB_unique_plate_details_fL.txt'\n",
    "output_file = 'pAGB_source_calib_date_plate.txt'\n",
    "\n",
    "add_plate_dates(source_with_plates_file, plate_metadata_file, output_file)\n",
    "\n",
    "print(f\"Output written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "de218ffe-89c3-42f8-8b94-e7116a0dbae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_433515788197481984.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_471908436438311680.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3108327343185135872.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3151417586128916864.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3238918336374596864.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_459182413984008448.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3589047952995134720.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_1328057763997734144.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3336558507975208448.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3334854780347915520.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3388902129107252992.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4334241408966611328.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3303343395568710016.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_173086700992466688.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3105987960396950784.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4109870908774509184.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4110550475656804864.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4568163710366782848.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_513671461473684352.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_994259335315643520.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4351018375858237952.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3624198034063995008.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3920735495441657728.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3422437684728294528.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_1369896865785991424.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_351149177434709760.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_565507868441719424.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_255225480926107392.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_1324742534573959424.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_1194929381434604800.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3032030620730261376.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3159640386918214528.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3156171118495247360.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4162959693758887424.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4128590918794710272.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4136944866387751552.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5707613169577769600.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4365451214021224320.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5620444471847839232.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2968265509022275840.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4124125282361429504.png\n",
      "Not enough data points for Gaia ID: 2351623413515105920 to plot a lightcurve\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5617989266685365120.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3497154104039422848.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5903310335089068416.png\n",
      "Not enough data points for Gaia ID: 5698817012142459136 to plot a lightcurve\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5980714063986945920.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5893945588395282304.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5849958457496943744.png\n",
      "Not enough data points for Gaia ID: 5849962851220246016 to plot a lightcurve\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5831295999979910656.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5932016212933920384.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6083719439934104832.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6066902993687172608.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5896479309853592448.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6084869868362934144.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5975083327400970752.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5946845601071213696.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4060159376692627840.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4686479751449676032.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4758015524139610880.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2902505745786910080.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5277809440015969792.png\n",
      "Not enough data points for Gaia ID: 5520238967817034880 to plot a lightcurve\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5351069693654349952.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5241806275407841664.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5462428643590805248.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5335675087769798272.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5343168568718268800.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_3469106382752903168.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6076326701687231872.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6130448958959242240.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6070128028770373888.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6083708479176016128.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5955201232284272384.png\n",
      "Not enough data points for Gaia ID: 5237007177683569536 to plot a lightcurve\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6060828565581083264.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5933063252888145920.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5335709477519159936.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2031794791233840128.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4061265519768800768.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4053880649927702656.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4109553493474085504.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5540178478053582592.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2030200671149815424.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2033763428091006720.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2006425553228658816.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_1836195688380634368.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2168803045330976768.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2015785313459952128.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_1803364717856260736.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2049034819957965312.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2074302426124470656.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2197298400984984064.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2060806470651334912.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4580154606223711872.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_1869422453048750336.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4582795323914832000.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4579182637944779264.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2056435602670418688.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2034134414507432064.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2055174630333744384.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4264026012336768000.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4282499452616310912.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4172337943816530432.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4516723883521069952.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4293369057089082112.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_1367102319545324288.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_1932229409071269248.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2096072103492979584.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_1976077657917533952.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2594762641717531008.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4067343654354938112.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4203848980711226112.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2179471159976791168.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4252449701157768960.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_1958757291756223104.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_2049984454412871296.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4240112390324832384.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4190636669164572928.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6879196723703009920.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6871175064823382912.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4158154754919296000.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6831062200578042624.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4042544062195042176.png\n",
      "Not enough data points for Gaia ID: 4049379725984965120 to plot a lightcurve\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4049331244394134912.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_5954670408684703872.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_4072427555640528000.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6715619076008049792.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6736747708089687936.png\n",
      "Saved: C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2\\lightcurve_6385794694664872320.png\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "\n",
    "def plot_lightcurves(data_file, output_dir):  # Added output_dir parameter\n",
    "    with open(data_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    gaia_data = {}\n",
    "\n",
    "    for source_info in data.values():\n",
    "        gaia_id = source_info.get('gaiaedr3_id')\n",
    "        bpmag = source_info.get('bpmag')\n",
    "        bpmag_error = source_info.get('bpmag_error')\n",
    "        date_str = source_info.get('date_orig')\n",
    "\n",
    "        if gaia_id is None or gaia_id == 0 or bpmag is None or date_str is None or bpmag_error is None or np.isnan(gaia_id) or np.isnan(bpmag) or np.isnan(bpmag_error) or bpmag < 0 or bpmag > 20 or bpmag_error > 0.5:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            date_obj = datetime.strptime(date_str, '%Y-%m-%d').date()\n",
    "        except ValueError as e:\n",
    "            print(f\"Invalid date format: {date_str}. Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        if gaia_id not in gaia_data:\n",
    "            gaia_data[gaia_id] = []\n",
    "        gaia_data[gaia_id].append((date_obj, bpmag, bpmag_error))\n",
    "\n",
    "    for gaia_id, observations in gaia_data.items():\n",
    "        if len(observations) < 2:\n",
    "            print(f\"Not enough data points for Gaia ID: {gaia_id} to plot a lightcurve\")\n",
    "            continue\n",
    "\n",
    "        dates, magnitudes, errors = zip(*observations)\n",
    "        dates = list(dates)\n",
    "        magnitudes = list(magnitudes)\n",
    "        errors = list(errors)\n",
    "\n",
    "        # Sort by date\n",
    "        sorted_indices = sorted(range(len(dates)), key=lambda k: dates[k])\n",
    "        sorted_dates = [dates[i] for i in sorted_indices]\n",
    "        sorted_magnitudes = [magnitudes[i] for i in sorted_indices]\n",
    "        sorted_errors = [errors[i] for i in sorted_indices]\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.errorbar(\n",
    "            sorted_dates,\n",
    "            sorted_magnitudes,\n",
    "            yerr=sorted_errors,\n",
    "            fmt='o',\n",
    "            capsize=4,\n",
    "            markersize=9,\n",
    "            color='red',\n",
    "            ecolor='red',\n",
    "            elinewidth=2,\n",
    "        )\n",
    "        plt.xlabel('Date', fontsize=12, color='black')\n",
    "        plt.ylabel('Bpmag', fontsize=12, color='black')\n",
    "        plt.title(f'Light Curve for Gaia ID: {gaia_id}', fontsize=14)\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "        # Improved date formatting on x-axis\n",
    "        plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "        plt.gcf().autofmt_xdate()\n",
    "\n",
    "        # Finer Ticks (replacing grid)\n",
    "        plt.minorticks_on()\n",
    "        plt.tick_params(axis='both', which='major', labelsize=10, length=6, width=1, colors='black') # added color here\n",
    "        plt.tick_params(axis='both', which='minor', length=3, width=1, colors='black') # added color here\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Create the output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"lightcurve_{gaia_id}.png\") # joined the path\n",
    "        plt.savefig(output_path, dpi=400)\n",
    "        print(f\"Saved: {output_path}\") # prints the full path\n",
    "        plt.close() # close the plot after saving\n",
    "\n",
    "data_file = 'pAGB_source_calib_date_plate.txt'\n",
    "output_dir = r'C:\\Users\\arkap\\Downloads\\TLS\\Downloads\\A2'  # Raw string for Windows paths\n",
    "plot_lightcurves(data_file, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b455ba-0439-4cd5-a564-e438fd6bda9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
